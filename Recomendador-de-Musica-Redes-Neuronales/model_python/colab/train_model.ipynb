{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqoU5YHdxQvK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "# Librer铆as de Deep Learning\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# =============================================================================\n",
        "# 1. CARGA Y PREPARACIN DE DATOS\n",
        "# =============================================================================\n",
        "print(\"--- 1) Cargando datos ---\")\n",
        "# Ajustar ruta si es necesario\n",
        "df = pd.read_csv(\"light_spotify_dataset.csv\")\n",
        "\n",
        "id_columnas = [\"song\", \"artist\"]\n",
        "cols_caracteristicas = [\n",
        "    \"Danceability\", \"Energy\", \"variance\", \"Tempo\", \"Loudness\",\n",
        "    \"Acousticness\", \"Instrumentalness\", \"Speechiness\",\n",
        "    \"Positiveness\", \"Popularity\", \"Liveness\"\n",
        "]\n",
        "\n",
        "cols_necesarias = id_columnas + cols_caracteristicas\n",
        "\n",
        "# Validaci贸n de columnas\n",
        "faltante = [c for c in cols_necesarias if c not in df.columns]\n",
        "if faltante:\n",
        "    raise ValueError(f\"Faltan columnas esperadas: {faltante}\")\n",
        "\n",
        "# Limpieza de nulos\n",
        "df = df.dropna(subset=cols_necesarias).reset_index(drop=True)\n",
        "\n",
        "# =============================================================================\n",
        "# 2. PREPROCESAMIENTO (SCALING)\n",
        "# =============================================================================\n",
        "print(\"--- 2) Escalando features ---\")\n",
        "caracteristicas_numericas = df[cols_caracteristicas].to_numpy(dtype=float)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_dense = scaler.fit_transform(caracteristicas_numericas)  # Matriz densa para K-Means y Red Neuronal\n",
        "X_sparse = csr_matrix(X_dense)                # Matriz sparse (opcional, para KNN legacy)\n",
        "\n",
        "# =============================================================================\n",
        "# 3. CLUSTERING (K-MEANS) - Contexto auxiliar\n",
        "# =============================================================================\n",
        "# Mantener KMeans para tener una etiqueta de 'grupo' general, aunque la recomendaci贸n\n",
        "# final la har谩 la Red Neuronal.\n",
        "print(\"--- 3) Generando Clusters (K-Means) ---\")\n",
        "\n",
        "k_opt = 6  # Ajustar seg煤n an谩lisis del codo previo\n",
        "kmeans = KMeans(n_clusters=k_opt, random_state=42, n_init=10)\n",
        "df[\"cluster\"] = kmeans.fit_predict(X_dense)\n",
        "\n",
        "nombres_clusters = {\n",
        "    0: \"Pop Urbano / Rap Mel贸dico / Trap Mainstream\",\n",
        "    1: \"Rock/Metal + Rap Intenso + Worship en vivo\",\n",
        "    2: \"Vocal Jazz\",      # Acousticness\n",
        "    3: \"Rap / Hip Hop\",         # Danceability / Speechiness\n",
        "    4: \"Rock/Industrial Atmosf茅rico & Electr贸nica Oscura\",  # Instrumentalness\n",
        "    5: \"Rock/Pop Energ茅tico y Optimista\"         # Tempo / Positiveness\n",
        "}\n",
        "\n",
        "\n",
        "df[\"nombre_cluster\"] = df[\"cluster\"].map(nombres_clusters)\n",
        "\n",
        "# =============================================================================\n",
        "# 4. RED NEURONAL (AUTOENCODER)\n",
        "# =============================================================================\n",
        "print(\"\\n--- 4) Entrenando Autoencoder ---\")\n",
        "\n",
        "input_dim = X_dense.shape[1]  # Cantidad de features (11 en este caso)\n",
        "latent_dim = 6                # Dimensi贸n del espacio latente (Embeddings)\n",
        "\n",
        "# --- Arquitectura del Modelo ---\n",
        "inputs = Input(shape=(input_dim,))\n",
        "encoded = Dense(12, activation=\"relu\")(inputs)          # Capa de compresi贸n 1\n",
        "latent = Dense(latent_dim, activation=\"relu\", name=\"latent_space\")(encoded) # Botella de cuello\n",
        "decoded = Dense(12, activation=\"relu\")(latent)          # Capa de descompresi贸n 1\n",
        "outputs = Dense(input_dim, activation=\"linear\")(decoded) # Reconstrucci贸n\n",
        "\n",
        "autoencoder = Model(inputs, outputs)\n",
        "encoder = Model(inputs, latent) # Modelo solo para extraer embeddings\n",
        "\n",
        "autoencoder.compile(optimizer=Adam(1e-3), loss=\"mse\")\n",
        "\n",
        "# --- Callbacks ---\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# --- Entrenamiento ---\n",
        "history = autoencoder.fit(\n",
        "    X_dense, X_dense,  # Autoencoder: entrada = salida\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- Gr谩fico de Loss ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.title(\"Entrenamiento del Autoencoder\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 5. GENERACIN DE EMBEDDINGS\n",
        "# =============================================================================\n",
        "print(\"--- 5) Generando Embeddings ---\")\n",
        "embeddings = encoder.predict(X_dense)\n",
        "print(f\"Shape de Embeddings: {embeddings.shape}\")\n",
        "\n",
        "# Agregar los embeddings al DataFrame para f谩cil acceso\n",
        "embed_cols = [f\"embed_{i}\" for i in range(latent_dim)]\n",
        "for i in range(latent_dim):\n",
        "    df[f\"embed_{i}\"] = embeddings[:, i]\n",
        "\n",
        "# =============================================================================\n",
        "# 6. GUARDADO DE ARTIFACTS\n",
        "# =============================================================================\n",
        "print(\"--- 6) Guardando modelo y artefactos ---\")\n",
        "\n",
        "# Agregar 'cols_caracteristicas' a la lista de columnas a guardar\n",
        "cols_to_save = [\"song\", \"artist\", \"cluster\", \"nombre_cluster\"] + cols_caracteristicas + embed_cols\n",
        "\n",
        "artifacts = {\n",
        "    \"scaler\": scaler,\n",
        "    \"cols_caracteristicas\": cols_caracteristicas,\n",
        "    \"kmeans_model\": kmeans,\n",
        "    \"nombres_clusters\": nombres_clusters,\n",
        "    \"autoencoder_model\": autoencoder,\n",
        "    \"encoder_model\": encoder,\n",
        "    \"embeddings\": embeddings,\n",
        "    # Guardamos el DF con las caracter铆sticas (Danceability, Energy, etc.)\n",
        "    \"dataframe_data\": df[cols_to_save].copy(),\n",
        "    \"input_dim\": input_dim\n",
        "}\n",
        "\n",
        "joblib.dump(artifacts, \"music_recommender_neural.joblib\")\n",
        "print(\" Saved: music_recommender_neural.joblib\")\n",
        "\n",
        "# =============================================================================\n",
        "# 7. SMOKE TEST (PRUEBA DE FUNCIONAMIENTO)\n",
        "# =============================================================================\n",
        "def recomendacion_manual(track_name, artist_name=None, top_k=5):\n",
        "    # 1. Buscar la canci贸n\n",
        "    mask = df[\"song\"].str.lower() == track_name.lower()\n",
        "    if artist_name:\n",
        "        mask &= df[\"artist\"].str.lower() == artist_name.lower()\n",
        "\n",
        "    matches = df[mask]\n",
        "\n",
        "    if matches.empty:\n",
        "        return f\"Canci贸n '{track_name}' no encontrada.\"\n",
        "\n",
        "    # Tomar el primer match\n",
        "    idx = matches.index[0]\n",
        "    target_vec = matches.loc[idx, embed_cols].values.reshape(1, -1)\n",
        "\n",
        "    # 2. Calcular distancia contra TODOS los embeddings\n",
        "    # Usar la matriz de embeddings generada anteriormente\n",
        "    dists = euclidean_distances(target_vec, df[embed_cols].values).flatten()\n",
        "\n",
        "    # 3. Ordenar y devolver\n",
        "    # argsort devuelve los 铆ndices ordenados por distancia menor a mayor\n",
        "    closest_indices = dists.argsort()[1:top_k+1] # [1:] para saltar la canci贸n misma\n",
        "\n",
        "    print(f\"\\nRecomendaciones para: {matches.loc[idx, 'song']} - {matches.loc[idx, 'artist']}\")\n",
        "    print(f\"Cluster base: {matches.loc[idx, 'nombre_cluster']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for i in closest_indices:\n",
        "        row = df.iloc[i]\n",
        "        print(f\"* {row['song']} ({row['artist']})\")\n",
        "        print(f\"  Cluster: {row['nombre_cluster']} | Distancia: {dists[i]:.4f}\")\n",
        "\n",
        "# Prueba manual\n",
        "try:\n",
        "    test_track = input(\"\\nIngres谩 una canci贸n para probar el modelo neuronal: \").strip()\n",
        "    if test_track:\n",
        "        recomendacion_manual(test_track, top_k=5)\n",
        "except Exception as e:\n",
        "    print(f\"Error en el test: {e}\")"
      ]
    }
  ]
}